name: CD - Train, Build & Deploy to GKE

on:
  push:
    branches: ["main","week_7"]

env:
  IMAGE_BASE: ${{ secrets.LOCATION }}-docker.pkg.dev/${{ secrets.GCP_PROJECT }}/${{ secrets.ARTIFACT_REPO }}/iris-api

jobs:
  build-deploy:
    runs-on: ubuntu-latest

    steps:
      # ðŸ§¾ Checkout repository
      - name: Checkout repository
        uses: actions/checkout@v4

      # ðŸ Set up Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      # ðŸ“¦ Install dependencies for training
      - name: Install dependencies for training
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install dvc[gs] mlflow joblib numpy scikit-learn

      # ðŸ“¥ Pull DVC data (if configured)
      - name: Pull DVC data (if configured)
        run: |
          if [ -f ".dvc/config" ]; then
            echo "Pulling dataset using DVC..."
            dvc pull || echo "No DVC remote configured or dataset already present"
          else
            echo "DVC not configured, using dataset from repo."
          fi
      - name: Clean old MLflow runs
        run: |
          rm -rf mlruns artifacts
          mkdir -p mlruns artifacts


      # ðŸ§  Run model training
      - name: Run model training
        run: |
          export HOME=$PWD         
          export MLFLOW_TRACKING_URI="file:./mlruns"
          export MLFLOW_ARTIFACT_ROOT="$PWD/artifacts"
          mkdir -p $MLFLOW_ARTIFACT_ROOT
          python train.py

      # âœ… Check model artifact exists
      - name: Check model artifact exists
        run: |
          if [ ! -f "artifacts/model_1.joblib" ]; then
            echo "âŒ Model artifact missing!"
            ls -la artifacts
            exit 1
          fi
          echo "âœ… Model artifact found."

      # ðŸ” Authenticate to Google Cloud
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      # â˜ï¸ Setup gcloud and GKE auth plugin
      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT }}
          install_components: 'gke-gcloud-auth-plugin'

      # ðŸ³ Configure Docker to use gcloud credential helper
      - name: Configure Docker authentication
        run: |
          gcloud auth configure-docker --quiet ${{ secrets.LOCATION }}-docker.pkg.dev

      # ðŸ—ï¸ Build Docker image
      - name: Build Docker image
        run: |
          IMAGE_TAG=${{ env.IMAGE_BASE }}:v${{ github.run_number }}
          docker build -t "${IMAGE_TAG}" .
          docker tag "${IMAGE_TAG}" "${{ env.IMAGE_BASE }}:latest"

      # ðŸš€ Push Docker image to Google Artifact Registry
      - name: Push Docker image
        run: |
          IMAGE_TAG=${{ env.IMAGE_BASE }}:v${{ github.run_number }}
          docker push "${IMAGE_TAG}"
          docker push "${{ env.IMAGE_BASE }}:latest"

      # ðŸ”§ Get GKE credentials
      - name: Get GKE credentials
        uses: google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: ${{ secrets.GKE_CLUSTER }}
          location: ${{ secrets.GKE_ZONE_OR_REGION }}
          project_id: ${{ secrets.GCP_PROJECT }}

      # ðŸš¢ Deploy to GKE
      - name: Deploy to GKE
        run: |
          IMAGE_TAG=${{ env.IMAGE_BASE }}:v${{ github.run_number }}
          echo "Deploying image: ${IMAGE_TAG}"

          echo "ðŸ”„ Applying deployment and service manifests..."
          kubectl apply -f k8s/deployment.yaml
          kubectl apply -f k8s/service.yaml

          echo "ðŸš€ Updating image in deployment..."
          kubectl set image deployment/iris-api iris-api=${IMAGE_TAG} --record || true

          echo "â³ Waiting for rollout to complete..."
          kubectl rollout status deployment/iris-api

          echo "âš™ï¸ Checking if HPA exists..."
          if ! kubectl get hpa iris-api-hpa >/dev/null 2>&1; then
            echo "ðŸ†• HPA not found â€” creating new autoscaler..."
            kubectl apply -f k8s/hpa.yml
          else
            echo "âœ… HPA already exists â€” updating configuration..."
            kubectl apply -f k8s/hpa.yml
          fi

          echo "ðŸ” Initial HPA status (before load)..."
          kubectl get hpa iris-api-hpa || echo "âš ï¸ Could not fetch HPA status."

          echo "â³ Waiting 60 seconds to observe autoscaling..."
          sleep 60

          echo "ðŸ”Ž Checking current pods and scaling..."
          kubectl get pods -o wide
          kubectl describe hpa iris-api-hpa | grep -E "Target|Desired|Current|Events"


      # ðŸ§© Apply manifests if first-time deployment
      # - name: Apply manifests (if needed)
      #   if: failure()
      #   run: |
      #     kubectl apply -f k8s/deployment.yaml
      #     kubectl apply -f k8s/service.yaml
      #     kubectl apply -f k8s/hpa.yml
          
      #     kubectl rollout status deployment/iris-api
  stress-test:
    runs-on: ubuntu-latest
    needs: build-deploy
    steps:
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up gcloud & get GKE credentials
        uses: google-github-actions/get-gke-credentials@v2
        with:
          cluster_name: ${{ secrets.GKE_CLUSTER }}
          location: ${{ secrets.GKE_ZONE_OR_REGION }}
          project_id: ${{ secrets.GCP_PROJECT }}

      - name: Install wrk for stress testing
        run: |
          sudo apt-get update
          sudo apt-get install -y wrk

      - name: Get LoadBalancer IP
        id: get-ip
        run: |
          SERVICE_IP=$(kubectl get svc iris-api-svc -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
          echo "SERVICE_IP=$SERVICE_IP" >> $GITHUB_ENV
          echo "Service available at: http://$SERVICE_IP:5000"

      - name: Stress Test (1000 concurrent requests)
        run: |
          echo "Running wrk with 1000 concurrent requests for 30s..."
          wrk -t12 -c1000 -d30s http://$SERVICE_IP:5000/

      - name: Observe HPA scaling behavior
        run: |
          echo "Checking autoscaler and pod count after load..."
          kubectl get hpa iris-api-hpa
          kubectl get pods -o wide

      - name: Restrict scaling to 1 pod
        run: |
          echo "Applying single-pod HPA (no scaling)..."
          kubectl apply -f k8s/hpa-single.yml
          kubectl get hpa iris-api-hpa

      - name: Stress Test (2000 concurrent requests with single pod)
        run: |
          echo "Running wrk with 2000 concurrent requests for 30s..."
          wrk -t12 -c2000 -d30s http://$SERVICE_IP:5000/

      - name: Observe bottlenecks
        run: |
          echo "Pods after restricted scaling test:"
          kubectl get hpa iris-api-hpa
          kubectl get pods -o wide
